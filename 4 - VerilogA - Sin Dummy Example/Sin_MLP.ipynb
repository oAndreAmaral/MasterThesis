{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, 10, 0.1)\n",
    "y = np.sin(X)\n",
    "\n",
    "X_in = Variable(torch.Tensor(X).cuda())\n",
    "Y_in = Variable(torch.Tensor(y).cuda())\n",
    "X_in = X_in.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7d481ad760>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineApproximator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SineApproximator, self).__init__()\n",
    "        self.regressor = nn.Sequential(nn.Linear(1, 500),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(500, 1))\n",
    "    def forward(self, x):\n",
    "        output = self.regressor(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model with the input parameters\n",
    "model = SineApproximator().cuda()\n",
    "\n",
    "# Define the Criterion: mean-squared error loss since we are working with regression problem\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamaral/.venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Epoch: 0, ----->loss: 1.00697E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 2, ----->loss: 1.27140E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 4, ----->loss: 5.25878E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 6, ----->loss: 8.08170E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 8, ----->loss: 2.47548E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 10, ----->loss: 1.74818E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 12, ----->loss: 6.36563E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 14, ----->loss: 1.86696E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 16, ----->loss: 6.30305E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 18, ----->loss: 8.93179E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 20, ----->loss: 1.09897E+00\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 22, ----->loss: 4.41620E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 24, ----->loss: 8.78998E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 26, ----->loss: 6.35905E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 28, ----->loss: 5.07776E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 30, ----->loss: 7.16671E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 32, ----->loss: 4.53136E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 34, ----->loss: 5.76582E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 36, ----->loss: 5.30115E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 38, ----->loss: 4.60733E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 40, ----->loss: 5.42526E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 42, ----->loss: 4.43213E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 44, ----->loss: 4.98878E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 46, ----->loss: 4.62489E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 48, ----->loss: 4.59148E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 50, ----->loss: 4.71677E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 52, ----->loss: 4.42929E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 54, ----->loss: 4.66335E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 56, ----->loss: 4.41470E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 58, ----->loss: 4.56469E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 60, ----->loss: 4.43860E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 62, ----->loss: 4.48646E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 64, ----->loss: 4.45330E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 66, ----->loss: 4.44194E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 68, ----->loss: 4.45325E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 70, ----->loss: 4.42152E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 72, ----->loss: 4.44544E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 74, ----->loss: 4.41371E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 76, ----->loss: 4.43613E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 78, ----->loss: 4.41118E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 80, ----->loss: 4.42820E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 82, ----->loss: 4.41049E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 84, ----->loss: 4.42235E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 86, ----->loss: 4.41031E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 88, ----->loss: 4.41830E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 90, ----->loss: 4.41026E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 92, ----->loss: 4.41557E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 94, ----->loss: 4.41024E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 96, ----->loss: 4.41371E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 98, ----->loss: 4.41025E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 100, ----->loss: 4.41245E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 102, ----->loss: 4.41029E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 104, ----->loss: 4.41157E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 106, ----->loss: 4.41034E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 108, ----->loss: 4.41097E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 110, ----->loss: 4.41039E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 112, ----->loss: 4.41056E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 114, ----->loss: 4.41041E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 116, ----->loss: 4.41031E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 118, ----->loss: 4.41039E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 120, ----->loss: 4.41017E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 122, ----->loss: 4.41034E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 124, ----->loss: 4.41011E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 126, ----->loss: 4.41027E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 128, ----->loss: 4.41011E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 130, ----->loss: 4.41020E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 132, ----->loss: 4.41012E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 134, ----->loss: 4.41014E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 136, ----->loss: 4.41013E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 138, ----->loss: 4.41010E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 140, ----->loss: 4.41012E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 142, ----->loss: 4.41008E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 144, ----->loss: 4.41011E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 146, ----->loss: 4.41008E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 148, ----->loss: 4.41009E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 150, ----->loss: 4.41008E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 152, ----->loss: 4.41008E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 154, ----->loss: 4.41008E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 156, ----->loss: 4.41007E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 158, ----->loss: 4.41007E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 160, ----->loss: 4.41007E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 162, ----->loss: 4.41007E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 164, ----->loss: 4.41007E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 166, ----->loss: 4.41006E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 168, ----->loss: 4.41006E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 170, ----->loss: 4.41006E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 172, ----->loss: 4.41006E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 174, ----->loss: 4.41006E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 176, ----->loss: 4.41006E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 178, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 180, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 182, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 184, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 186, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 188, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 190, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 192, ----->loss: 4.41005E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 194, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 196, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 198, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 200, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 202, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 204, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 206, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 208, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 210, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 212, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 214, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 216, ----->loss: 4.41004E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 218, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 220, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 222, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 224, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 226, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 228, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 230, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 232, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 234, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 236, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 238, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 240, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 242, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 244, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 246, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 248, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 250, ----->loss: 4.41003E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 252, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 254, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 256, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 258, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 260, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 262, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 264, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 266, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 268, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 270, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 272, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 274, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 276, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 278, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 280, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 282, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 284, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 286, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 288, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 290, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 292, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 294, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 296, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 298, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 300, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 302, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 304, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 306, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 308, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 310, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 312, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 314, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 316, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 318, ----->loss: 4.41002E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 320, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 322, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 324, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 326, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 328, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 330, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 332, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 334, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 336, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 338, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 340, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 342, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 344, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 346, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 348, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 350, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 352, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 354, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 356, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 358, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 360, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 362, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 364, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 366, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 368, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 370, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 372, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 374, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 376, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 378, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 380, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 382, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 384, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 386, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 388, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 390, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 392, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 394, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 396, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 398, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 400, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 402, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 404, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 406, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 408, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 410, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 412, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 414, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 416, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 418, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 420, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 422, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 424, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 426, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 428, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 430, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 432, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 434, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 436, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 438, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 440, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 442, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 444, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 446, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 448, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 450, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 452, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 454, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 456, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 458, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 460, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 462, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 464, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 466, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 468, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 470, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 472, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 474, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 476, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 478, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 480, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 482, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 484, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 486, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 488, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 490, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 492, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 494, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 496, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 498, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 500, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 502, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 504, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 506, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 508, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 510, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 512, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 514, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 516, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 518, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 520, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 522, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 524, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 526, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 528, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 530, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 532, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 534, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 536, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 538, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 540, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 542, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 544, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 546, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 548, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 550, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 552, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 554, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 556, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 558, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 560, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 562, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 564, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 566, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 568, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 570, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 572, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 574, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 576, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 578, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 580, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 582, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 584, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 586, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 588, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 590, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 592, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 594, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 596, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 598, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 600, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 602, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 604, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 606, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 608, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 610, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 612, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 614, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 616, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 618, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 620, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 622, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 624, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 626, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 628, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 630, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 632, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 634, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 636, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 638, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 640, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 642, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 644, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 646, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 648, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 650, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 652, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 654, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 656, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 658, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 660, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 662, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 664, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 666, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 668, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 670, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 672, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 674, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 676, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 678, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 680, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 682, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 684, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 686, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 688, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 690, ----->loss: 4.41001E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 692, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 694, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 696, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 698, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 700, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 702, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 704, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 706, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 708, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 710, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 712, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 714, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 716, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 718, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 720, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 722, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 724, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 726, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 728, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 730, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 732, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 734, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 736, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 738, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 740, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 742, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 744, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 746, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 748, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 750, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 752, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 754, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 756, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 758, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 760, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 762, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 764, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 766, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 768, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 770, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 772, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 774, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 776, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 778, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 780, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 782, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 784, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 786, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 788, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 790, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 792, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 794, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 796, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 798, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 800, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 802, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 804, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 806, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 808, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 810, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 812, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 814, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 816, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 818, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 820, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 822, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 824, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 826, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 828, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 830, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 832, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 834, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 836, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 838, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 840, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 842, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 844, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 846, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 848, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 850, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 852, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 854, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 856, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 858, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 860, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 862, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 864, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 866, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 868, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 870, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 872, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 874, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 876, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 878, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 880, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 882, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 884, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 886, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 888, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 890, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 892, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 894, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 896, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 898, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 900, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 902, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 904, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 906, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 908, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 910, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 912, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 914, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 916, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 918, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 920, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 922, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 924, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 926, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 928, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 930, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 932, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 934, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 936, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 938, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 940, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 942, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 944, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 946, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 948, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 950, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 952, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 954, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 956, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 958, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 960, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 962, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 964, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 966, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 968, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 970, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 972, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 974, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 976, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 978, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 980, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 982, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 984, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 986, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 988, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 990, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 992, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 994, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 996, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 998, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1000, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1002, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1004, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1006, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1008, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1010, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1012, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1014, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1016, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1018, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1020, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1022, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1024, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1026, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1028, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1030, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1032, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1034, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1036, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1038, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1040, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1042, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1044, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1046, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1048, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1050, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1052, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1054, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1056, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1058, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1060, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1062, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1064, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1066, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1068, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1070, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1072, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1074, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1076, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1078, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1080, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1082, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1084, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1086, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1088, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1090, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1092, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1094, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1096, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1098, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1100, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1102, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1104, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1106, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1108, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1110, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1112, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1114, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1116, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1118, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1120, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1122, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1124, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1126, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1128, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1130, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1132, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1134, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1136, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1138, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1140, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1142, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1144, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1146, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1148, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1150, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1152, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1154, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1156, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1158, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1160, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1162, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1164, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1166, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1168, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1170, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1172, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1174, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1176, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1178, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1180, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1182, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1184, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1186, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1188, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1190, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1192, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1194, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1196, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1198, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1200, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1202, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1204, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1206, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1208, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1210, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1212, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1214, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1216, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1218, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1220, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1222, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1224, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1226, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1228, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1230, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1232, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1234, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1236, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1238, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1240, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1242, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1244, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1246, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1248, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1250, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1252, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1254, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1256, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1258, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1260, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1262, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1264, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1266, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1268, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1270, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1272, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1274, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1276, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1278, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1280, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1282, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1284, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1286, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1288, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1290, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1292, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1294, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1296, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1298, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1300, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1302, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1304, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1306, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1308, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1310, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1312, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1314, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1316, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1318, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1320, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1322, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1324, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1326, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1328, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1330, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1332, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1334, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1336, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1338, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1340, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1342, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1344, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1346, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1348, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1350, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1352, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1354, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1356, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1358, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1360, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1362, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1364, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1366, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1368, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1370, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1372, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1374, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1376, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1378, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1380, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1382, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1384, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1386, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1388, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1390, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1392, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1394, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1396, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1398, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1400, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1402, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1404, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1406, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1408, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1410, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1412, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1414, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1416, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1418, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1420, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1422, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1424, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1426, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1428, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1430, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1432, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1434, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1436, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1438, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1440, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1442, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1444, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1446, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1448, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1450, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1452, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1454, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1456, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1458, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1460, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1462, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1464, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1466, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1468, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1470, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1472, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1474, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1476, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1478, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1480, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1482, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1484, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1486, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1488, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1490, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1492, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1494, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1496, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1498, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1500, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1502, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1504, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1506, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1508, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1510, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1512, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1514, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1516, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1518, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1520, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1522, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1524, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1526, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1528, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1530, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1532, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1534, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1536, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1538, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1540, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1542, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1544, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1546, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1548, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1550, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1552, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1554, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1556, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1558, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1560, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1562, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1564, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1566, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1568, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1570, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1572, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1574, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1576, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1578, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1580, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1582, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1584, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1586, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1588, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1590, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1592, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1594, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1596, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1598, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1600, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1602, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1604, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1606, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1608, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1610, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1612, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1614, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1616, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1618, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1620, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1622, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1624, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1626, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1628, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1630, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1632, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1634, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1636, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1638, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1640, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1642, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1644, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1646, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1648, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1650, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1652, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1654, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1656, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1658, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1660, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1662, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1664, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1666, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1668, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1670, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1672, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1674, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1676, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1678, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1680, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1682, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1684, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1686, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1688, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1690, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1692, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1694, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1696, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1698, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1700, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1702, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1704, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1706, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1708, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1710, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1712, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1714, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1716, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1718, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1720, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1722, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1724, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1726, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1728, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1730, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1732, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1734, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1736, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1738, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1740, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1742, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1744, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1746, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1748, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1750, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1752, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1754, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1756, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1758, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1760, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1762, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1764, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1766, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1768, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1770, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1772, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1774, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1776, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1778, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1780, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1782, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1784, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1786, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1788, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1790, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1792, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1794, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1796, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1798, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1800, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1802, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1804, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1806, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1808, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1810, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1812, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1814, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1816, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1818, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1820, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1822, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1824, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1826, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1828, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1830, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1832, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1834, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1836, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1838, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1840, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1842, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1844, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1846, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1848, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1850, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1852, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1854, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1856, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1858, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1860, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1862, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1864, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1866, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1868, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1870, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1872, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1874, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1876, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1878, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1880, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1882, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1884, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1886, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1888, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1890, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1892, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1894, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1896, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1898, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1900, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1902, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1904, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1906, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1908, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1910, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1912, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1914, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1916, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1918, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1920, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1922, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1924, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1926, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1928, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1930, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1932, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1934, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1936, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1938, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1940, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1942, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1944, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1946, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1948, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1950, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1952, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1954, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1956, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1958, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1960, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1962, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1964, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1966, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1968, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1970, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1972, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1974, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1976, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1978, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1980, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1982, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1984, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1986, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1988, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1990, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1992, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1994, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1996, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n",
      "-----> Epoch: 1998, ----->loss: 4.41000E-01\n",
      "Learning Rate: 5.000000E-03 \n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs\n",
    "number_of_epochs = 2000\n",
    "\n",
    "# Variable to store the losses per epoch\n",
    "losses = []\n",
    "\n",
    "# Instanciate that the model is in training mode\n",
    "model.train()\n",
    "\n",
    "# For every epoch defined...\n",
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "    # Initialize the gradient to avoid value agregations\n",
    "    optimizer.zero_grad()       \n",
    "\n",
    "    # Predict the model using the training set\n",
    "    y_pred = model(X_in)\n",
    "\n",
    "    # Obtain the loss and the error\n",
    "    loss = criterion(y_pred, Y_in)\n",
    "            \n",
    "        \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "\n",
    "    # Append the losses to make the plot\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print the results\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"-----> Epoch: %d, ----->loss: %.5E\" % (epoch, loss.item()))\n",
    "        print(\"Learning Rate: %.6E \" % optimizer.param_groups[0][\"lr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7d0aec3a00>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(X_in)\n",
    "pred = pred.cpu().data.numpy()\n",
    "x_plot = X_in.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7d0ab8e880>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X,y)\n",
    "plt.plot(X,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7d0ab70ac0>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FC1 Weights and Bias Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = []\n",
    "w1 = model.regressor[0].weight.detach().cpu().numpy()\n",
    "\n",
    "first = '{%f' %w1[0]\n",
    "middle_out = ',%f' %w1[1]\n",
    "last = '}'\n",
    "\n",
    "middle = first + middle_out\n",
    "\n",
    "for i in (n+2 for n in range(np.size(model.regressor[0].weight,0)-2)):\n",
    "    aux = ',%f' %w1[i]\n",
    "    middle = middle + aux\n",
    "w1_VA = middle + last\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = []\n",
    "b1 = model.regressor[0].bias.detach().cpu().numpy()\n",
    "\n",
    "first = '{%f' %b1[0]\n",
    "middle_out = ',%f' %b1[1]\n",
    "last = '}'\n",
    "\n",
    "middle = first + middle_out\n",
    "\n",
    "for i in (n+2 for n in range(np.size(model.regressor[0].bias,0)-2)):\n",
    "    aux = ',%f' %b1[i]\n",
    "    middle = middle + aux\n",
    "b1_VA = middle + last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write VerilogA Code\n",
    "import csv\n",
    "\n",
    "with open('Weights_Layer_1.va', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['  parameter real w1[499:0] = %s' %w1_VA, ';'])\n",
    "    writer.writerow(['  parameter real b1[499:0] = %s' %b1_VA, ';'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e367e3eba0c249af86b9dca2e8a5cf4bb1dd64b5ae1ee422094ad095610b564"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
