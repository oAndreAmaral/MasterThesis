{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import pandas as pd\n",
    "import modin.pandas as n_pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Datatable Import\n",
    "import datatable as dt\n",
    "\n",
    "# Deep Learning Pytorch Library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchinfo import summary\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "seed = 123\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "\n",
    "# Seed for DataLoader\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = 123\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset Features and Labels\n",
    "\n",
    "Both datasets are pre-processed and concatenated, using different code snipets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import using datatable\n",
    "X = dt.fread(\"X.csv\")\n",
    "Y = dt.fread(\"Y.csv\")\n",
    "\n",
    "# Convert to pandas\n",
    "X = X.to_pandas()\n",
    "Y = Y.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dimensions part of the X vector\n",
    "X.iloc[:,6:(X.shape[1]+1)] = scaler.fit_transform(X.iloc[:,6:(X.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Variable Type and Give to a DataLoader\n",
    "The dataloader will allow to create batches to feed the network smoothly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all dataset for train\n",
    "all_dataX = Variable(torch.Tensor(X.values)) # .cuda()\n",
    "all_dataY = Variable(torch.Tensor(Y.values)) # .cuda()\n",
    "\n",
    "# Delete X and Y from memory\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dataset\n",
    "ds = TensorDataset(all_dataX, all_dataY)\n",
    "del all_dataX, all_dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "BatchSize = 10000\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(123)\n",
    "\n",
    "# Create the DataLoader\n",
    "dl = DataLoader(ds, batch_size=BatchSize, shuffle=False, num_workers= 8, pin_memory=True, drop_last=True, generator=g, worker_init_fn= seed_worker) #shuffle was at false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model LSTM OTA1 (lna1)\n",
    "The model is a LSTM neural network followed by 2 fully connected layers.  \n",
    "For that purpose the PyTorch library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, batch_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Define Variables to be used in the \"forward\" path\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_init_states = int(batch_size/2)\n",
    "\n",
    "        # initialize the hidden and cell states - Stateful LSTM\n",
    "        self.hn = Variable(torch.zeros(1, self.batch_init_states, 450).cuda())\n",
    "        self.cn = Variable(torch.zeros(1, self.batch_init_states, 450).cuda())\n",
    "        \n",
    "        # Define the layers that will be used\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) # LSTM Layer\n",
    "        self.fc1 = nn.Linear(hidden_size + 28, 250) # First Linear layer (+ 28 because of the 28 features for the dimensions for the devices) 250\n",
    "        self.elu = nn.ELU() # Activation function to allows the model to destinguish de dimensions\n",
    "        self.dropout = nn.Dropout(p = 0.1) # Dropout to regularization\n",
    "        self.fc2 = nn.Linear(250, num_classes) # Second Linear Layer\n",
    "        self.fc3 = nn.Linear(28,num_classes)\n",
    "        \n",
    "    def forward(self, x, dimensions):\n",
    "        \n",
    "        # Propagate the input through LSTM module\n",
    "        ula, (self.hn, self.cn) = self.lstm(x, (self.hn.cuda(), self.cn.cuda()))\n",
    "             \n",
    "        # Ajust lstm output shape\n",
    "        hn_out = (self.hn).view(-1, self.hidden_size)\n",
    "\n",
    "        # Concatenate the lstm output and the dimension vector\n",
    "        in_fc = torch.cat((hn_out.cuda(), dimensions.cuda()), dim=1).cuda()\n",
    "\n",
    "        # Propagate the data through the fully conected layers\n",
    "        out = self.fc1(in_fc)\n",
    "        out = self.elu(out)\n",
    "        out = self.fc2(out) \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate the Model, Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "DataParallel                             --\n",
       "├─LSTM: 1-1                              --\n",
       "│    └─LSTM: 2-1                         817,200\n",
       "│    └─Linear: 2-2                       119,750\n",
       "│    └─ELU: 2-3                          --\n",
       "│    └─Dropout: 2-4                      --\n",
       "│    └─Linear: 2-5                       502\n",
       "│    └─Linear: 2-6                       58\n",
       "=================================================================\n",
       "Total params: 937,510\n",
       "Trainable params: 937,510\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Model with the input parameters\n",
    "lstm = LSTM(num_classes=2, input_size=2, hidden_size=450, num_layers=1, batch_size= BatchSize).cuda() #have 450!!\n",
    "lstm = torch.nn.DataParallel(lstm, device_ids=[0,1]).cuda()\n",
    "\n",
    "# Define the Criterion: mean-squared error loss since we are working with regression problem\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define the Optimizer\n",
    "optimizer = torch.optim.AdamW(lstm.parameters(), lr=0.00005)\n",
    "\n",
    "# Adaptative Learning Rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.7, patience=2, min_lr = 0.000001)\n",
    "\n",
    "# Print the model structure\n",
    "summary(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Epoch: 0, ----->loss: 6.33861E-03\n",
      "Learning Rate: 5.000000E-05 \n",
      "-----> Epoch: 2, ----->loss: 2.43615E-03\n",
      "Learning Rate: 5.000000E-05 \n",
      "-----> Epoch: 4, ----->loss: 2.21910E-03\n",
      "Learning Rate: 5.000000E-05 \n",
      "-----> Epoch: 6, ----->loss: 2.27093E-03\n",
      "Learning Rate: 5.000000E-05 \n",
      "-----> Epoch: 8, ----->loss: 2.04750E-03\n",
      "Learning Rate: 3.500000E-05 \n",
      "-----> Epoch: 10, ----->loss: 1.98089E-03\n",
      "Learning Rate: 3.500000E-05 \n",
      "-----> Epoch: 12, ----->loss: 1.81319E-03\n",
      "Learning Rate: 3.500000E-05 \n",
      "-----> Epoch: 14, ----->loss: 1.53125E-03\n",
      "Learning Rate: 3.500000E-05 \n",
      "-----> Epoch: 16, ----->loss: 1.37524E-03\n",
      "Learning Rate: 3.500000E-05 \n",
      "-----> Epoch: 18, ----->loss: 1.27999E-03\n",
      "Learning Rate: 3.500000E-05 \n",
      "\n",
      "Duration: 57 Min\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs\n",
    "number_of_epochs = 20\n",
    "\n",
    "# Define the start time \n",
    "start_time = time.time()\n",
    "\n",
    "# Variable to store the losses per epoch\n",
    "losses = []\n",
    "errors = []\n",
    "\n",
    "# Instanciate that the model is in training mode\n",
    "lstm.train()\n",
    "\n",
    "# For every epoch defined...\n",
    "for epoch in range(number_of_epochs):\n",
    "    \n",
    "    # Feed data in batches\n",
    "    for batch_features, batch_labels in dl:\n",
    "        \n",
    "        # Extract input waves from all batch, reshape to (xxx,3,2) and send to cuda\n",
    "        input_waves = batch_features[:,0:6]\n",
    "        input_waves = input_waves.reshape(input_waves.shape[0], input_waves.shape[1] // 2, 2)\n",
    "        input_waves = input_waves.cuda()\n",
    "\n",
    "        # Extract the dimensions from all batch\n",
    "        input_dimensions = batch_features[:,6:(batch_features.shape[1]+1)]\n",
    "        input_dimension = input_dimensions.cuda()\n",
    "\n",
    "        # Pass batch labels to GPU\n",
    "        batch_labels = batch_labels.cuda()\n",
    "\n",
    "        # Initialize the gradient to avoid value agregations\n",
    "        optimizer.zero_grad()       \n",
    "\n",
    "        # enable autocasting for forward pass\n",
    "        # * speeds up linear math operations\n",
    "        # * speeds up memory-limited operations by acessing to half of bytes compared to single precision\n",
    "        # * reduces memory rrequirements for training models\n",
    "        with autocast():\n",
    "            # Predict the model using the training set\n",
    "            y_pred = lstm(input_waves, input_dimensions)\n",
    "\n",
    "            # Obtain the loss and the error\n",
    "            loss = criterion(y_pred, batch_labels)\n",
    "            error = y_pred - batch_labels\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(lstm.parameters(), max_norm = 0.25) # gradient cliping to avoid exploding gradients\n",
    "        optimizer.step()\n",
    "\n",
    "    # Append the losses to make the plot\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Append the errors to obtain the metrics to create the noise\n",
    "    errors.append(error)\n",
    "\n",
    "    # Adaptative Learning Rate\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Print the results\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"-----> Epoch: %d, ----->loss: %.5E\" % (epoch, loss.item()))\n",
    "        print(\"Learning Rate: %.6E \" % optimizer.param_groups[0][\"lr\"])\n",
    "            \n",
    "# Print the execution time\n",
    "print(f'\\nDuration: {(time.time() - start_time)/60:.0f} Min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10000, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_new = torch.stack(errors,dim = 0).cpu().data.numpy()\n",
    "errors_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004383777\n",
      "0.046118375\n"
     ]
    }
   ],
   "source": [
    "errors_mean = np.mean(errors_new)\n",
    "errors_stdv = np.std(errors_new)\n",
    "print(errors_mean)\n",
    "print(errors_stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses along the epochs\n",
    "with torch.no_grad():\n",
    "    # If the train ends normaly\n",
    "    if epoch == number_of_epochs:\n",
    "        plt.plot(range(epoch+1), losses)    \n",
    "        plt.ylabel('RMSE Loss')\n",
    "        plt.xlabel('epoch');\n",
    "        \n",
    "    # If the train is shut down \n",
    "    else:\n",
    "        plt.plot(range(epoch+1), losses)    \n",
    "        plt.ylabel('RMSE Loss')\n",
    "        plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': lstm.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, '/home/aamaral/Desktop/BigDataset/Evaluation/Final_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e367e3eba0c249af86b9dca2e8a5cf4bb1dd64b5ae1ee422094ad095610b564"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
